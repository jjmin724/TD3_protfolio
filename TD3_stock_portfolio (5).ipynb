{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 finrlalpaca_trade_api quantstats exchange_calendars stockstats wrds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OswMBf5nVI2",
        "outputId": "16b4cca2-9ca9-4cce-b538-72a98bafbba3",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: finrl in /usr/local/lib/python3.11/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy.linalg as la\n",
        "from functools import reduce\n",
        "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import PortfolioOptimizationEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "id": "Y7hkv2tcRzY5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KT7I4yMOAV",
        "outputId": "d85a18e0-d8ef-432d-f71d-822391030a45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "TECH_FEATURES_PATH = '/content/drive/MyDrive/객지프/tech_features_top50.pt'\n",
        "PRED_NEXT_CLOSE_PATH = '/content/drive/MyDrive/객지프/pred_next_close.csv'\n",
        "\n",
        "# Define dates\n",
        "TRAIN_START_DATE = '2021-01-01'\n",
        "TRAIN_END_DATE = '2025-06-06'\n",
        "TEST_START_DATE = '2023-01-01'\n",
        "TEST_END_DATE = '2023-12-31'\n",
        "N = 252  # Lookback period for turbulence\n",
        "\n",
        "# Load tech features\n",
        "tech_data = torch.load(TECH_FEATURES_PATH)\n",
        "tensor = tech_data['features'].numpy()\n",
        "dates = pd.to_datetime(tech_data['meta']['dates'])\n",
        "symbols = tech_data['meta']['symbols']\n",
        "columns = tech_data['meta']['columns']\n",
        "\n",
        "# Create DataFrame from tech features\n",
        "df_list = []\n",
        "for i, tic in enumerate(symbols):\n",
        "    df_stock = pd.DataFrame(tensor[:, i, :], columns=columns)\n",
        "    df_stock['date'] = dates\n",
        "    df_stock['tic'] = tic\n",
        "    df_list.append(df_stock)\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "df.set_index(['date', 'tic'], inplace=True)\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❶ 예측 CSV → Series 변환\n",
        "# ---------------------------------------------------------------\n",
        "pred_df = pd.read_csv(\n",
        "    PRED_NEXT_CLOSE_PATH,\n",
        "    index_col=0,\n",
        "    parse_dates=True\n",
        ")\n",
        "pred_series = pred_df.stack()\n",
        "pred_series.index.set_names(['date', 'tic'], inplace=True)\n",
        "pred_series.name = 'pred_next_close'\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❷ feature DF 와 병합  ← ★ 이 줄이 빠져 있었음!\n",
        "# ---------------------------------------------------------------\n",
        "df = df.join(pred_series, how='left')\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❸ Daily return 계산 (NaN→0)\n",
        "# ---------------------------------------------------------------\n",
        "df['return'] = df.groupby('tic')['Close'].pct_change().fillna(0)\n",
        "df_ret = df['return'].unstack('tic')          # (T,N)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❹ Turbulence 계산 (정규화 + NaN 방어)\n",
        "# ---------------------------------------------------------------\n",
        "turbulence = []\n",
        "for t in range(N, len(df_ret)):\n",
        "    past = df_ret.iloc[t-N:t]\n",
        "    past = past.loc[:, past.any()]            # 전부 0 열 제거\n",
        "\n",
        "    mu = past.mean()\n",
        "    with np.errstate(invalid='ignore'):\n",
        "        Sigma = past.cov()\n",
        "\n",
        "    if Sigma.isna().values.any() or np.isinf(Sigma.values).any():\n",
        "        turbulence.append(np.nan); continue   # 방어\n",
        "\n",
        "    Sigma += np.eye(Sigma.shape[0]) * 1e-6    # regularize\n",
        "    r_t  = df_ret.iloc[t][Sigma.columns]\n",
        "    diff = r_t - mu\n",
        "    d_t  = diff.T @ np.linalg.inv(Sigma) @ diff\n",
        "    turbulence.append(d_t)\n",
        "\n",
        "turbulence_df = pd.DataFrame({\n",
        "    'date'      : df_ret.index[N:],\n",
        "    'turbulence': turbulence\n",
        "})\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❺ 병합 후 결측 0 대체\n",
        "# ---------------------------------------------------------------\n",
        "df = (df.reset_index()\n",
        "        .merge(turbulence_df, on='date', how='left')\n",
        "        .set_index(['date', 'tic'])\n",
        "        .sort_index())\n",
        "df.fillna({'turbulence': 0}, inplace=True)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ❻ Train/Test 분리 & NaN 제거\n",
        "# ---------------------------------------------------------------\n",
        "FEATURES = columns + ['pred_next_close', 'turbulence']\n",
        "\n",
        "df_train = df.loc[TRAIN_START_DATE:TRAIN_END_DATE].dropna(subset=FEATURES).reset_index()\n",
        "df_test  = df.loc[TEST_START_DATE :TEST_END_DATE ].dropna(subset=FEATURES).reset_index()\n",
        "\n",
        "features = FEATURES\n",
        "print(\"train rows:\", len(df_train), \" test rows:\", len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A6yU2cDZ1uw",
        "outputId": "bd11499a-fe58-4792-e06a-54583bd9f7b5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train rows: 75999  test rows: 17155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Portfolio Optimization Environment\n",
        "class CustomPortfolioOptimizationEnv(PortfolioOptimizationEnv):\n",
        "    def __init__(self, *args, commission_rate=0.0025, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.commission_rate = commission_rate\n",
        "\n",
        "    def step(self, action):\n",
        "        # Normalize action to sum to 1\n",
        "        action = action / np.sum(action)\n",
        "        # Get current and previous dates\n",
        "        current_date = self.dates[self.day]\n",
        "        previous_date = self.dates[self.day - 1] if self.day > 0 else None\n",
        "        # Get y_t: price relatives\n",
        "        if previous_date is not None:\n",
        "            y_t = self.df.loc[current_date, 'Close'].values / self.df.loc[previous_date, 'Close'].values\n",
        "        else:\n",
        "            y_t = np.ones(len(self.tickers))\n",
        "        # Compute w_t': intermediate weights\n",
        "        if self.day > 0:\n",
        "            w_prev = self.weights\n",
        "            p_prev = self.portfolio_value\n",
        "            # Compute p_t' = p_prev * (y_t · w_prev)\n",
        "            p_t_prime = p_prev * np.dot(y_t, w_prev)\n",
        "            # Compute w_t' = (y_t * w_prev) / (y_t · w_prev)\n",
        "            w_t_prime = (y_t * w_prev) / np.dot(y_t, w_prev)\n",
        "        else:\n",
        "            w_t_prime = action  # initial weights\n",
        "            p_t_prime = self.initial_amount\n",
        "        # Now, w_t = action\n",
        "        w_t = action\n",
        "        # Compute μ_t iteratively\n",
        "        c = self.commission_rate\n",
        "        sum_term = lambda mu: np.sum(np.maximum(w_t_prime - mu * w_t, 0))\n",
        "        f_mu = lambda mu: 1 - 2 * c * sum_term(mu)\n",
        "        # Initial guess\n",
        "        mu = 1 - c * np.sum(np.abs(w_t_prime - w_t))\n",
        "        # Iterate until convergence\n",
        "        tolerance = 1e-6\n",
        "        max_iter = 100\n",
        "        for _ in range(max_iter):\n",
        "            mu_new = f_mu(mu)\n",
        "            if abs(mu_new - mu) < tolerance:\n",
        "                break\n",
        "            mu = mu_new\n",
        "        else:\n",
        "            print(\"Warning: μ_t did not converge\")\n",
        "        mu_t = mu\n",
        "        # Compute p_t = mu_t * p_t_prime\n",
        "        p_t = mu_t * p_t_prime\n",
        "        # Update portfolio value\n",
        "        self.portfolio_value = p_t\n",
        "        # Update weights\n",
        "        self.weights = w_t\n",
        "        # Compute reward: log return\n",
        "        if self.day > 0:\n",
        "            reward = np.log(p_t / p_prev)\n",
        "        else:\n",
        "            reward = 0\n",
        "        # Increment day\n",
        "        self.day += 1\n",
        "        # Check done\n",
        "        done = self.day >= len(self.dates)\n",
        "        # Get next state\n",
        "        state = self._get_state()\n",
        "        info = {}\n",
        "        return state, reward, done, info\n",
        "\n",
        "# Set up environments\n",
        "env_train = CustomPortfolioOptimizationEnv(\n",
        "    df=df_train,\n",
        "    initial_amount=1000000,\n",
        "    comission_fee_pct=0.0025,\n",
        "    time_window=50,\n",
        "    features=features,\n",
        "    valuation_feature='Close',\n"
        ")\n",
        "env_test = CustomPortfolioOptimizationEnv(\n",
        "    df=df_test,\n",
        "    initial_amount=1000000,\n",
        "    comission_fee_pct=0.0025,\n",
        "    time_window=50,\n",
        "    features=features,\n",
        "    valuation_feature='Close',\n"
        ")\n",
        "\n",
        "# Define TD3 parameters\n",
        "TD3_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 1000000,\n",
        "    \"learning_rate\": 0.001,\n",
        "}\n",
        "\n",
        "# Create and train TD3 agent\n",
        "agent = DRLAgent(env=env_train)\n",
        "model_td3 = agent.get_model(\"td3\", model_kwargs=TD3_PARAMS)\n",
        "trained_td3 = agent.train_model(model=model_td3, tb_log_name='td3', total_timesteps=50000)\n",
        "\n",
        "# Evaluate on test data\n",
        "account_memory, actions_memory = agent.DRL_prediction(model=trained_td3, environment=env_test)\n",
        "\n",
        "# Compute and print cumulative return\n",
        "cumulative_return = account_memory[-1] / account_memory[0] - 1\n",
        "print(f\"Cumulative return: {cumulative_return}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "XNcnN1ASZOmV",
        "outputId": "ba61e07f-a3f8-418a-def3-f1ecdf714ef6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n",
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n",
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing ['Open', 'High', 'Low', 'Close', 'Volume', 'Spread', 'TickVolume', 'mv100', 'mv50', 'mv9', 'bb_bbm', 'bb_bbh', 'bb_bbl', 'rsi14', 'rsi50', 'rsimv9', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'w1', 'pred_next_close', 'turbulence'] by previous time...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n",
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n",
            "/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_temporal_variation[prev_column] = df_temporal_variation.groupby(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-955483f7af39>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Set up environments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m env_train = CustomPortfolioOptimizationEnv(\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0minitial_amount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-955483f7af39>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, commission_rate, *args, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomPortfolioOptimizationEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPortfolioOptimizationEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommission_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommission_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommission_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, initial_amount, order_df, return_last_action, normalize_df, reward_scaling, comission_fee_model, comission_fee_pct, features, valuation_feature, time_column, time_format, tic_column, tics_in_portfolio, time_window, cwd, new_gym_api)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtics_in_portfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# dims and spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/finrl/meta/env_portfolio_optimization/env_portfolio_optimization.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, order, normalize, tics_in_portfolio)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# transform str to datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         self._df_price_variation[self._time_column] = pd.to_datetime(\n\u001b[1;32m    527\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df_price_variation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    }
  ]
}